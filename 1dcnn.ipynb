{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Conv1D,InputLayer,Dense,Dropout,Flatten,MaxPooling1D,BatchNormalization,MaxPool1D,Add,Input,concatenate,Activation\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>heartbeat_signals</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9912297987616655,0.9435330436439665,0.764677...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9714822034884503,0.9289687459588268,0.572932...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0,0.9591487564065292,0.7013782792997189,0.23...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.9757952826275774,0.9340884687738161,0.659636...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0,0.055816398940721094,0.26129357194994196,0...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                  heartbeat_signals  label\n",
       "0   0  0.9912297987616655,0.9435330436439665,0.764677...    0.0\n",
       "1   1  0.9714822034884503,0.9289687459588268,0.572932...    0.0\n",
       "2   2  1.0,0.9591487564065292,0.7013782792997189,0.23...    2.0\n",
       "3   3  0.9757952826275774,0.9340884687738161,0.659636...    0.0\n",
       "4   4  0.0,0.055816398940721094,0.26129357194994196,0...    2.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./data/train.csv',encoding='utf-8')\n",
    "test=pd.read_csv('./data/testA.csv',encoding='utf-8')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>heartbeat_signals</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>119995</td>\n",
       "      <td>1.0,0.8330283177934747,0.6340472606311671,0.63...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>119996</td>\n",
       "      <td>1.0,0.8259705825857048,0.4521053488322387,0.08...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>119997</td>\n",
       "      <td>0.951744840752379,0.9162611283848351,0.6675251...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>119998</td>\n",
       "      <td>0.9276692903808186,0.6771898159607004,0.242906...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>119999</td>\n",
       "      <td>0.6653212231837624,0.527064114047737,0.5166625...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                  heartbeat_signals  label\n",
       "119995  119995  1.0,0.8330283177934747,0.6340472606311671,0.63...    0.0\n",
       "119996  119996  1.0,0.8259705825857048,0.4521053488322387,0.08...    0.0\n",
       "119997  119997  0.951744840752379,0.9162611283848351,0.6675251...    2.0\n",
       "119998  119998  0.9276692903808186,0.6771898159607004,0.242906...    0.0\n",
       "119999  119999  0.6653212231837624,0.527064114047737,0.5166625...    0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#转换数据类型来减小数据占用内存\n",
    "def reduce_mem_usage(df):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2 \n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2 \n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 157.93 MB\n",
      "Memory usage after optimization is: 39.67 MB\n",
      "Decreased by 74.9%\n",
      "Memory usage of dataframe is 31.43 MB\n",
      "Memory usage after optimization is: 7.90 MB\n",
      "Decreased by 74.9%\n"
     ]
    }
   ],
   "source": [
    "# 简单预处理\n",
    "train_list = []\n",
    "\n",
    "for items in train.values:\n",
    "    train_list.append([items[0]] + [float(i) for i in items[1].split(',')] + [items[2]])\n",
    "\n",
    "train = pd.DataFrame(np.array(train_list))\n",
    "train.columns = ['id'] + ['s_'+str(i) for i in range(len(train_list[0])-2)] + ['label']\n",
    "train = reduce_mem_usage(train)\n",
    "\n",
    "test_list=[]\n",
    "for items in test.values:\n",
    "    test_list.append([items[0]] + [float(i) for i in items[1].split(',')])\n",
    "\n",
    "test = pd.DataFrame(np.array(test_list))\n",
    "test.columns = ['id'] + ['s_'+str(i) for i in range(len(test_list[0])-1)]\n",
    "test = reduce_mem_usage(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 205) (20000, 205)\n"
     ]
    }
   ],
   "source": [
    "Y = train['label']\n",
    "X = train.drop(['id','label'],axis=1)\n",
    "test= test.drop(['id'],axis=1)\n",
    "print(np.shape(X),np.shape(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_sum(y_pre,y_tru):\n",
    "    y_pre=np.array(y_pre)\n",
    "    y_tru=np.array(y_tru)\n",
    "    loss=sum(sum(abs(y_pre-y_tru)))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).reshape(-1,205,1)   #因为模型读入数据要求是三维\n",
    "test = np.array(test).reshape(-1,205,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = to_categorical(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildmodel3():  #线上172，用172当预训练再训练168\n",
    "    inputs=Input(shape=(205,1))\n",
    "    x1 = Conv1D(32,kernel_size=32, strides=1, padding='SAME',activation='relu')(inputs)\n",
    "    x2 = Conv1D(32,kernel_size=16, strides=1, padding='SAME',activation='relu')(inputs)\n",
    "    x3 = Conv1D(32,kernel_size=48, strides=1, padding='SAME',activation='relu')(inputs)\n",
    "    x4 = Add()([x1,x2,x3])\n",
    "    x = BatchNormalization()(x4)    \n",
    "    \n",
    "    x = Conv1D(64,kernel_size=16, strides=1, padding='SAME',activation='relu')(x4)\n",
    "    x = Conv1D(128,kernel_size=8, strides=1, padding='SAME',activation='relu')(x)\n",
    "    \n",
    "    x = MaxPool1D(pool_size=4, strides=2, padding='SAME')(x)\n",
    "    x = Dropout(rate=0.25)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512,activation='relu')(x)\n",
    "    x = Dense(1024,activation='relu')(x)\n",
    "    output = Dense(4,activation='softmax')(x)\n",
    "    model = Model(inputs=inputs,outputs=output)\n",
    "   \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 205, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 205, 32)      1056        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 205, 32)      544         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 205, 32)      1568        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 205, 32)      0           conv1d[0][0]                     \n",
      "                                                                 conv1d_1[0][0]                   \n",
      "                                                                 conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 205, 64)      32832       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 205, 128)     65664       conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 103, 128)     0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 103, 128)     0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 13184)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          6750720     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         525312      dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4)            4100        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 7,381,796\n",
      "Trainable params: 7,381,796\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = buildmodel3()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_model(train_x, train_y, test):\n",
    "    folds = 10\n",
    "    seeds = [600]\n",
    "    tests = []\n",
    "    cv_scores = []\n",
    "    \n",
    "    for seed in seeds:\n",
    "        kf = KFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "        for i, (train_index, valid_index) in enumerate(kf.split(train_x, train_y)):\n",
    "            print('************************************ 随机种子{}***第{}折 ************************************'.format(seed,str(i+1)))\n",
    "            trn_x, trn_y, val_x, val_y = train_x[train_index], train_y[train_index], train_x[valid_index], train_y[valid_index]\n",
    "        \n",
    "            #model = buildmodel3()\n",
    "            model = tf.keras.models.load_model('/root/model/cnnbestnew_425_1_2000.h5')\n",
    "            model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0009),\n",
    "             loss = 'categorical_crossentropy',\n",
    "            metrics = ['acc']\n",
    "             ) \n",
    "            \n",
    "            best_weights_filepath = '/root/model/cnnbestnew_429_{}_{}.h5'.format(i+1,seed)\n",
    "            \n",
    "            earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_acc',patience=4,verbose=2,mode='max')\n",
    "            reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=3, mode='min',verbose=2,factor=0.5)\n",
    "            saveBestModel = tf.keras.callbacks.ModelCheckpoint(best_weights_filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max',save_weights_only=False)\n",
    "            \n",
    "            my_callbacks = [earlystop,reduce_lr,saveBestModel]\n",
    "            model.fit(trn_x,trn_y,epochs=30,batch_size=256,validation_data=(val_x,val_y),shuffle=True,callbacks=my_callbacks)\n",
    "    \n",
    "          #注意，这里要重新加载保存的模型，即最优模型；否则他会用最后一次迭代的模型去推理\n",
    "            model = tf.keras.models.load_model('/root/model/cnnbestnew_429_{}_{}.h5'.format(i+1,seed))\n",
    "#             test_pred = model.predict(test)                 \n",
    "#             test_temp = pd.DataFrame(np.zeros((20000,4)))\n",
    "#             for t in range(len(test_pred)):\n",
    "#                 a = pd.DataFrame(test_pred).iloc[t,:].argmax(0)\n",
    "#                 test_temp.iloc[t,a] = 1\n",
    "    \n",
    "#             val_pred = pd.DataFrame(val_pred)\n",
    "#             for col in range(4):\n",
    "#                 val_pred.iloc[:,col] = val_pred.iloc[:,col].apply(lambda x:0 if x<0.5 else 1)\n",
    "            \n",
    "            val_pred = model.predict(val_x)\n",
    "            val_temp = pd.DataFrame(np.zeros((10000,4)))\n",
    "            for t in range(len(val_pred)):\n",
    "                a = pd.DataFrame(val_pred).iloc[t,:].argmax(0)\n",
    "                val_temp.iloc[t,a] = 1\n",
    "                \n",
    "            #tests.append(test_temp)\n",
    "            score=abs_sum(val_y, val_temp)\n",
    "            cv_scores.append(score)\n",
    "            print(score)\n",
    "        print(\"score_mean:{}\".format(np.mean(cv_scores)))\n",
    "\n",
    "   # return tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************ 随机种子600***第1折 ************************************\n",
      "Train on 90000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "89344/90000 [============================>.] - ETA: 0s - loss: 0.0121 - acc: 0.9968\n",
      "Epoch 00001: val_acc improved from -inf to 0.99720, saving model to /root/model/cnnbestnew_429_1_600.h5\n",
      "90000/90000 [==============================] - 6s 68us/sample - loss: 0.0121 - acc: 0.9968 - val_loss: 0.0084 - val_acc: 0.9972\n",
      "Epoch 2/30\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9973\n",
      "Epoch 00002: val_acc did not improve from 0.99720\n",
      "90000/90000 [==============================] - 5s 55us/sample - loss: 0.0095 - acc: 0.9973 - val_loss: 0.0102 - val_acc: 0.9966\n",
      "Epoch 3/30\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9972\n",
      "Epoch 00003: val_acc did not improve from 0.99720\n",
      "90000/90000 [==============================] - 5s 56us/sample - loss: 0.0101 - acc: 0.9972 - val_loss: 0.0165 - val_acc: 0.9956\n",
      "Epoch 4/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9980\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00044999999227002263.\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.99720\n",
      "90000/90000 [==============================] - 5s 55us/sample - loss: 0.0067 - acc: 0.9980 - val_loss: 0.0107 - val_acc: 0.9972\n",
      "Epoch 5/30\n",
      "89088/90000 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9990\n",
      "Epoch 00005: val_acc improved from 0.99720 to 0.99840, saving model to /root/model/cnnbestnew_429_1_600.h5\n",
      "90000/90000 [==============================] - 7s 83us/sample - loss: 0.0033 - acc: 0.9990 - val_loss: 0.0059 - val_acc: 0.9984\n",
      "Epoch 6/30\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9994\n",
      "Epoch 00006: val_acc did not improve from 0.99840\n",
      "90000/90000 [==============================] - 5s 55us/sample - loss: 0.0016 - acc: 0.9994 - val_loss: 0.0074 - val_acc: 0.9982\n",
      "Epoch 7/30\n",
      "89344/90000 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9994\n",
      "Epoch 00007: val_acc did not improve from 0.99840\n",
      "90000/90000 [==============================] - 5s 56us/sample - loss: 0.0017 - acc: 0.9994 - val_loss: 0.0063 - val_acc: 0.9983\n",
      "Epoch 8/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9996\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00022499999613501132.\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.99840\n",
      "90000/90000 [==============================] - 5s 55us/sample - loss: 0.0012 - acc: 0.9996 - val_loss: 0.0083 - val_acc: 0.9982\n",
      "Epoch 9/30\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 5.9559e-04 - acc: 0.9998\n",
      "Epoch 00009: val_acc did not improve from 0.99840\n",
      "90000/90000 [==============================] - 5s 56us/sample - loss: 5.9464e-04 - acc: 0.9998 - val_loss: 0.0088 - val_acc: 0.9981\n",
      "Epoch 00009: early stopping\n",
      "32.0\n",
      "************************************ 随机种子600***第2折 ************************************\n",
      "Train on 90000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "89088/90000 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9969\n",
      "Epoch 00001: val_acc improved from -inf to 0.99680, saving model to /root/model/cnnbestnew_429_2_600.h5\n",
      "90000/90000 [==============================] - 9s 98us/sample - loss: 0.0106 - acc: 0.9969 - val_loss: 0.0141 - val_acc: 0.9968\n",
      "Epoch 2/30\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9972\n",
      "Epoch 00002: val_acc improved from 0.99680 to 0.99760, saving model to /root/model/cnnbestnew_429_2_600.h5\n",
      "90000/90000 [==============================] - 5s 61us/sample - loss: 0.0095 - acc: 0.9972 - val_loss: 0.0104 - val_acc: 0.9976\n",
      "Epoch 3/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9972\n",
      "Epoch 00003: val_acc did not improve from 0.99760\n",
      "90000/90000 [==============================] - 5s 56us/sample - loss: 0.0095 - acc: 0.9972 - val_loss: 0.0097 - val_acc: 0.9974\n",
      "Epoch 4/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9983\n",
      "Epoch 00004: val_acc did not improve from 0.99760\n",
      "90000/90000 [==============================] - 5s 55us/sample - loss: 0.0055 - acc: 0.9983 - val_loss: 0.0090 - val_acc: 0.9976\n",
      "Epoch 5/30\n",
      "89088/90000 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9981\n",
      "Epoch 00005: val_acc improved from 0.99760 to 0.99770, saving model to /root/model/cnnbestnew_429_2_600.h5\n",
      "90000/90000 [==============================] - 5s 61us/sample - loss: 0.0061 - acc: 0.9981 - val_loss: 0.0112 - val_acc: 0.9977\n",
      "Epoch 6/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9979\n",
      "Epoch 00006: val_acc did not improve from 0.99770\n",
      "90000/90000 [==============================] - 5s 56us/sample - loss: 0.0069 - acc: 0.9980 - val_loss: 0.0135 - val_acc: 0.9960\n",
      "Epoch 7/30\n",
      "89344/90000 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9977\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00044999999227002263.\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.99770\n",
      "90000/90000 [==============================] - 5s 56us/sample - loss: 0.0081 - acc: 0.9977 - val_loss: 0.0118 - val_acc: 0.9971\n",
      "Epoch 8/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9992\n",
      "Epoch 00008: val_acc improved from 0.99770 to 0.99790, saving model to /root/model/cnnbestnew_429_2_600.h5\n",
      "90000/90000 [==============================] - 6s 62us/sample - loss: 0.0021 - acc: 0.9992 - val_loss: 0.0088 - val_acc: 0.9979\n",
      "Epoch 9/30\n",
      "89344/90000 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9997\n",
      "Epoch 00009: val_acc did not improve from 0.99790\n",
      "90000/90000 [==============================] - 5s 56us/sample - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0095 - val_acc: 0.9975\n",
      "Epoch 10/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9994\n",
      "Epoch 00010: val_acc did not improve from 0.99790\n",
      "90000/90000 [==============================] - 5s 56us/sample - loss: 0.0017 - acc: 0.9994 - val_loss: 0.0096 - val_acc: 0.9978\n",
      "Epoch 11/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9996\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00022499999613501132.\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.99790 to 0.99810, saving model to /root/model/cnnbestnew_429_2_600.h5\n",
      "90000/90000 [==============================] - 5s 61us/sample - loss: 0.0012 - acc: 0.9996 - val_loss: 0.0096 - val_acc: 0.9981\n",
      "Epoch 12/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 6.7747e-04 - acc: 0.9998\n",
      "Epoch 00012: val_acc improved from 0.99810 to 0.99820, saving model to /root/model/cnnbestnew_429_2_600.h5\n",
      "90000/90000 [==============================] - 5s 59us/sample - loss: 6.7463e-04 - acc: 0.9998 - val_loss: 0.0100 - val_acc: 0.9982\n",
      "Epoch 13/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 5.6385e-04 - acc: 0.9999\n",
      "Epoch 00013: val_acc did not improve from 0.99820\n",
      "90000/90000 [==============================] - 5s 56us/sample - loss: 5.6156e-04 - acc: 0.9999 - val_loss: 0.0117 - val_acc: 0.9981\n",
      "Epoch 14/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 5.0112e-04 - acc: 0.9999\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00011249999806750566.\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.99820\n",
      "90000/90000 [==============================] - 5s 56us/sample - loss: 4.9899e-04 - acc: 0.9999 - val_loss: 0.0109 - val_acc: 0.9981\n",
      "Epoch 15/30\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 2.8182e-04 - acc: 0.9999\n",
      "Epoch 00015: val_acc did not improve from 0.99820\n",
      "90000/90000 [==============================] - 5s 57us/sample - loss: 2.8167e-04 - acc: 0.9999 - val_loss: 0.0118 - val_acc: 0.9982\n",
      "Epoch 16/30\n",
      "89088/90000 [============================>.] - ETA: 0s - loss: 1.6800e-04 - acc: 1.0000\n",
      "Epoch 00016: val_acc did not improve from 0.99820\n",
      "90000/90000 [==============================] - 5s 57us/sample - loss: 1.6647e-04 - acc: 1.0000 - val_loss: 0.0123 - val_acc: 0.9981\n",
      "Epoch 00016: early stopping\n",
      "36.0\n",
      "************************************ 随机种子600***第3折 ************************************\n",
      "Train on 90000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "89344/90000 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9969\n",
      "Epoch 00001: val_acc improved from -inf to 0.99640, saving model to /root/model/cnnbestnew_429_3_600.h5\n",
      "90000/90000 [==============================] - 7s 73us/sample - loss: 0.0115 - acc: 0.9969 - val_loss: 0.0093 - val_acc: 0.9964\n",
      "Epoch 2/30\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9971\n",
      "Epoch 00002: val_acc did not improve from 0.99640\n",
      "90000/90000 [==============================] - 5s 56us/sample - loss: 0.0104 - acc: 0.9971 - val_loss: 0.0114 - val_acc: 0.9963\n",
      "Epoch 3/30\n",
      "89344/90000 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9980\n",
      "Epoch 00003: val_acc improved from 0.99640 to 0.99680, saving model to /root/model/cnnbestnew_429_3_600.h5\n",
      "90000/90000 [==============================] - 5s 59us/sample - loss: 0.0063 - acc: 0.9980 - val_loss: 0.0100 - val_acc: 0.9968\n",
      "Epoch 4/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9973\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00044999999227002263.\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.99680\n",
      "90000/90000 [==============================] - 5s 55us/sample - loss: 0.0098 - acc: 0.9973 - val_loss: 0.0220 - val_acc: 0.9948\n",
      "Epoch 5/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9988\n",
      "Epoch 00005: val_acc improved from 0.99680 to 0.99790, saving model to /root/model/cnnbestnew_429_3_600.h5\n",
      "90000/90000 [==============================] - 5s 61us/sample - loss: 0.0038 - acc: 0.9988 - val_loss: 0.0073 - val_acc: 0.9979\n",
      "Epoch 6/30\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9993\n",
      "Epoch 00006: val_acc did not improve from 0.99790\n",
      "90000/90000 [==============================] - 5s 55us/sample - loss: 0.0023 - acc: 0.9993 - val_loss: 0.0077 - val_acc: 0.9979\n",
      "Epoch 7/30\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9995\n",
      "Epoch 00007: val_acc improved from 0.99790 to 0.99820, saving model to /root/model/cnnbestnew_429_3_600.h5\n",
      "90000/90000 [==============================] - 5s 60us/sample - loss: 0.0015 - acc: 0.9995 - val_loss: 0.0078 - val_acc: 0.9982\n",
      "Epoch 8/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9993\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00022499999613501132.\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.99820\n",
      "90000/90000 [==============================] - 5s 56us/sample - loss: 0.0023 - acc: 0.9993 - val_loss: 0.0089 - val_acc: 0.9977\n",
      "Epoch 9/30\n",
      "89344/90000 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9996\n",
      "Epoch 00009: val_acc did not improve from 0.99820\n",
      "90000/90000 [==============================] - 5s 54us/sample - loss: 0.0011 - acc: 0.9996 - val_loss: 0.0103 - val_acc: 0.9981\n",
      "Epoch 10/30\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9996\n",
      "Epoch 00010: val_acc improved from 0.99820 to 0.99840, saving model to /root/model/cnnbestnew_429_3_600.h5\n",
      "90000/90000 [==============================] - 8s 89us/sample - loss: 0.0011 - acc: 0.9996 - val_loss: 0.0082 - val_acc: 0.9984\n",
      "Epoch 11/30\n",
      "89088/90000 [============================>.] - ETA: 0s - loss: 4.8504e-04 - acc: 0.9998\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00011249999806750566.\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.99840\n",
      "90000/90000 [==============================] - 5s 56us/sample - loss: 4.8638e-04 - acc: 0.9998 - val_loss: 0.0093 - val_acc: 0.9980\n",
      "Epoch 12/30\n",
      "89344/90000 [============================>.] - ETA: 0s - loss: 3.6991e-04 - acc: 0.9999\n",
      "Epoch 00012: val_acc did not improve from 0.99840\n",
      "90000/90000 [==============================] - 5s 55us/sample - loss: 3.6751e-04 - acc: 0.9999 - val_loss: 0.0097 - val_acc: 0.9981\n",
      "Epoch 13/30\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 2.3471e-04 - acc: 0.9999\n",
      "Epoch 00013: val_acc did not improve from 0.99840\n",
      "90000/90000 [==============================] - 5s 56us/sample - loss: 2.3434e-04 - acc: 0.9999 - val_loss: 0.0097 - val_acc: 0.9981\n",
      "Epoch 14/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 3.2633e-04 - acc: 0.9999\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 5.624999903375283e-05.\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.99840\n",
      "90000/90000 [==============================] - 5s 56us/sample - loss: 3.3265e-04 - acc: 0.9999 - val_loss: 0.0104 - val_acc: 0.9982\n",
      "Epoch 00014: early stopping\n",
      "32.0\n",
      "************************************ 随机种子600***第4折 ************************************\n",
      "Train on 90000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9969\n",
      "Epoch 00001: val_acc improved from -inf to 0.99680, saving model to /root/model/cnnbestnew_429_4_600.h5\n",
      "90000/90000 [==============================] - 9s 98us/sample - loss: 0.0122 - acc: 0.9969 - val_loss: 0.0102 - val_acc: 0.9968\n",
      "Epoch 2/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9970\n",
      "Epoch 00002: val_acc improved from 0.99680 to 0.99720, saving model to /root/model/cnnbestnew_429_4_600.h5\n",
      "90000/90000 [==============================] - 5s 59us/sample - loss: 0.0097 - acc: 0.9971 - val_loss: 0.0125 - val_acc: 0.9972\n",
      "Epoch 3/30\n",
      "89344/90000 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9976\n",
      "Epoch 00003: val_acc did not improve from 0.99720\n",
      "90000/90000 [==============================] - 5s 57us/sample - loss: 0.0090 - acc: 0.9976 - val_loss: 0.0140 - val_acc: 0.9952\n",
      "Epoch 4/30\n",
      "89344/90000 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9976\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00044999999227002263.\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.99720\n",
      "90000/90000 [==============================] - 5s 56us/sample - loss: 0.0073 - acc: 0.9976 - val_loss: 0.0142 - val_acc: 0.9966\n",
      "Epoch 5/30\n",
      "89344/90000 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9992\n",
      "Epoch 00005: val_acc improved from 0.99720 to 0.99770, saving model to /root/model/cnnbestnew_429_4_600.h5\n",
      "90000/90000 [==============================] - 5s 61us/sample - loss: 0.0022 - acc: 0.9992 - val_loss: 0.0099 - val_acc: 0.9977\n",
      "Epoch 6/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9994\n",
      "Epoch 00006: val_acc did not improve from 0.99770\n",
      "90000/90000 [==============================] - 5s 56us/sample - loss: 0.0016 - acc: 0.9994 - val_loss: 0.0115 - val_acc: 0.9975\n",
      "Epoch 7/30\n",
      "89088/90000 [============================>.] - ETA: 0s - loss: 9.8809e-04 - acc: 0.9997\n",
      "Epoch 00007: val_acc did not improve from 0.99770\n",
      "90000/90000 [==============================] - 5s 56us/sample - loss: 9.8188e-04 - acc: 0.9997 - val_loss: 0.0157 - val_acc: 0.9973\n",
      "Epoch 8/30\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9995\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00022499999613501132.\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.99770\n",
      "90000/90000 [==============================] - 5s 57us/sample - loss: 0.0013 - acc: 0.9995 - val_loss: 0.0143 - val_acc: 0.9975\n",
      "Epoch 9/30\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 8.8621e-04 - acc: 0.9997\n",
      "Epoch 00009: val_acc improved from 0.99770 to 0.99780, saving model to /root/model/cnnbestnew_429_4_600.h5\n",
      "90000/90000 [==============================] - 6s 61us/sample - loss: 8.8504e-04 - acc: 0.9997 - val_loss: 0.0122 - val_acc: 0.9978\n",
      "Epoch 10/30\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9996\n",
      "Epoch 00010: val_acc did not improve from 0.99780\n",
      "90000/90000 [==============================] - 5s 55us/sample - loss: 0.0012 - acc: 0.9996 - val_loss: 0.0132 - val_acc: 0.9975\n",
      "Epoch 11/30\n",
      "89088/90000 [============================>.] - ETA: 0s - loss: 7.7843e-04 - acc: 0.9997\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00011249999806750566.\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.99780\n",
      "90000/90000 [==============================] - 5s 57us/sample - loss: 7.7123e-04 - acc: 0.9997 - val_loss: 0.0138 - val_acc: 0.9975\n",
      "Epoch 12/30\n",
      "89088/90000 [============================>.] - ETA: 0s - loss: 4.0716e-04 - acc: 0.9999\n",
      "Epoch 00012: val_acc improved from 0.99780 to 0.99810, saving model to /root/model/cnnbestnew_429_4_600.h5\n",
      "90000/90000 [==============================] - 5s 60us/sample - loss: 4.0332e-04 - acc: 0.9999 - val_loss: 0.0114 - val_acc: 0.9981\n",
      "Epoch 13/30\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 2.8549e-04 - acc: 0.9999\n",
      "Epoch 00013: val_acc improved from 0.99810 to 0.99820, saving model to /root/model/cnnbestnew_429_4_600.h5\n",
      "90000/90000 [==============================] - 7s 77us/sample - loss: 2.8504e-04 - acc: 0.9999 - val_loss: 0.0122 - val_acc: 0.9982\n",
      "Epoch 14/30\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 2.0549e-04 - acc: 0.9999\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 5.624999903375283e-05.\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.99820\n",
      "90000/90000 [==============================] - 5s 56us/sample - loss: 2.0518e-04 - acc: 0.9999 - val_loss: 0.0122 - val_acc: 0.9980\n",
      "Epoch 15/30\n",
      "89344/90000 [============================>.] - ETA: 0s - loss: 1.9426e-04 - acc: 1.0000\n",
      "Epoch 00015: val_acc did not improve from 0.99820\n",
      "90000/90000 [==============================] - 5s 55us/sample - loss: 1.9327e-04 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 0.9980\n",
      "Epoch 16/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 1.9399e-04 - acc: 0.9999\n",
      "Epoch 00016: val_acc did not improve from 0.99820\n",
      "90000/90000 [==============================] - 5s 55us/sample - loss: 1.9315e-04 - acc: 0.9999 - val_loss: 0.0127 - val_acc: 0.9980\n",
      "Epoch 17/30\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 1.4173e-04 - acc: 1.0000\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 2.8124999516876414e-05.\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.99820\n",
      "90000/90000 [==============================] - 5s 56us/sample - loss: 1.4150e-04 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 0.9980\n",
      "Epoch 00017: early stopping\n",
      "36.0\n",
      "************************************ 随机种子600***第5折 ************************************\n",
      "Train on 90000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9963\n",
      "Epoch 00001: val_acc improved from -inf to 0.99120, saving model to /root/model/cnnbestnew_429_5_600.h5\n",
      "90000/90000 [==============================] - 6s 70us/sample - loss: 0.0130 - acc: 0.9963 - val_loss: 0.0295 - val_acc: 0.9912\n",
      "Epoch 2/30\n",
      "89344/90000 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9976\n",
      "Epoch 00002: val_acc improved from 0.99120 to 0.99580, saving model to /root/model/cnnbestnew_429_5_600.h5\n",
      "90000/90000 [==============================] - 8s 84us/sample - loss: 0.0081 - acc: 0.9976 - val_loss: 0.0123 - val_acc: 0.9958\n",
      "Epoch 3/30\n",
      "89344/90000 [============================>.] - ETA: 0s - loss: 0.0065 - acc: 0.9980\n",
      "Epoch 00003: val_acc improved from 0.99580 to 0.99730, saving model to /root/model/cnnbestnew_429_5_600.h5\n",
      "90000/90000 [==============================] - 5s 59us/sample - loss: 0.0065 - acc: 0.9980 - val_loss: 0.0103 - val_acc: 0.9973\n",
      "Epoch 4/30\n",
      "89344/90000 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9975\n",
      "Epoch 00004: val_acc did not improve from 0.99730\n",
      "90000/90000 [==============================] - 5s 55us/sample - loss: 0.0083 - acc: 0.9975 - val_loss: 0.0166 - val_acc: 0.9937\n",
      "Epoch 5/30\n",
      "89088/90000 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9968\n",
      "Epoch 00005: val_acc did not improve from 0.99730\n",
      "90000/90000 [==============================] - 5s 55us/sample - loss: 0.0110 - acc: 0.9968 - val_loss: 0.0159 - val_acc: 0.9956\n",
      "Epoch 6/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9975\n",
      "Epoch 00006: val_acc did not improve from 0.99730\n",
      "90000/90000 [==============================] - 5s 56us/sample - loss: 0.0087 - acc: 0.9975 - val_loss: 0.0101 - val_acc: 0.9968\n",
      "Epoch 7/30\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9982\n",
      "Epoch 00007: val_acc did not improve from 0.99730\n",
      "90000/90000 [==============================] - 5s 55us/sample - loss: 0.0062 - acc: 0.9982 - val_loss: 0.0094 - val_acc: 0.9971\n",
      "Epoch 00007: early stopping\n",
      "54.0\n",
      "************************************ 随机种子600***第6折 ************************************\n",
      "Train on 90000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "89088/90000 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9967\n",
      "Epoch 00001: val_acc improved from -inf to 0.99710, saving model to /root/model/cnnbestnew_429_6_600.h5\n",
      "90000/90000 [==============================] - 9s 104us/sample - loss: 0.0126 - acc: 0.9967 - val_loss: 0.0093 - val_acc: 0.9971\n",
      "Epoch 2/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9973\n",
      "Epoch 00002: val_acc did not improve from 0.99710\n",
      "90000/90000 [==============================] - 5s 55us/sample - loss: 0.0095 - acc: 0.9973 - val_loss: 0.0112 - val_acc: 0.9963\n",
      "Epoch 3/30\n",
      "89088/90000 [============================>.] - ETA: 0s - loss: 0.0082 - acc: 0.9972\n",
      "Epoch 00003: val_acc improved from 0.99710 to 0.99730, saving model to /root/model/cnnbestnew_429_6_600.h5\n",
      "90000/90000 [==============================] - 6s 62us/sample - loss: 0.0082 - acc: 0.9972 - val_loss: 0.0119 - val_acc: 0.9973\n",
      "Epoch 4/30\n",
      "89088/90000 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9981\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00044999999227002263.\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.99730\n",
      "90000/90000 [==============================] - 5s 56us/sample - loss: 0.0065 - acc: 0.9981 - val_loss: 0.0149 - val_acc: 0.9954\n",
      "Epoch 5/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9987\n",
      "Epoch 00005: val_acc improved from 0.99730 to 0.99800, saving model to /root/model/cnnbestnew_429_6_600.h5\n",
      "90000/90000 [==============================] - 5s 59us/sample - loss: 0.0037 - acc: 0.9988 - val_loss: 0.0070 - val_acc: 0.9980\n",
      "Epoch 6/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9993\n",
      "Epoch 00006: val_acc did not improve from 0.99800\n",
      "90000/90000 [==============================] - 5s 55us/sample - loss: 0.0022 - acc: 0.9993 - val_loss: 0.0064 - val_acc: 0.9980\n",
      "Epoch 7/30\n",
      "89088/90000 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9994\n",
      "Epoch 00007: val_acc did not improve from 0.99800\n",
      "90000/90000 [==============================] - 5s 56us/sample - loss: 0.0016 - acc: 0.9994 - val_loss: 0.0122 - val_acc: 0.9972\n",
      "Epoch 8/30\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9992\n",
      "Epoch 00008: val_acc did not improve from 0.99800\n",
      "90000/90000 [==============================] - 5s 55us/sample - loss: 0.0023 - acc: 0.9992 - val_loss: 0.0145 - val_acc: 0.9968\n",
      "Epoch 9/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9990\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00022499999613501132.\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.99800 to 0.99830, saving model to /root/model/cnnbestnew_429_6_600.h5\n",
      "90000/90000 [==============================] - 6s 61us/sample - loss: 0.0032 - acc: 0.9990 - val_loss: 0.0081 - val_acc: 0.9983\n",
      "Epoch 10/30\n",
      "89344/90000 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9997\n",
      "Epoch 00010: val_acc did not improve from 0.99830\n",
      "90000/90000 [==============================] - 5s 56us/sample - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0077 - val_acc: 0.9980\n",
      "Epoch 11/30\n",
      "89088/90000 [============================>.] - ETA: 0s - loss: 5.2500e-04 - acc: 0.9998\n",
      "Epoch 00011: val_acc did not improve from 0.99830\n",
      "90000/90000 [==============================] - 5s 57us/sample - loss: 5.2374e-04 - acc: 0.9998 - val_loss: 0.0074 - val_acc: 0.9983\n",
      "Epoch 12/30\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 8.2469e-04 - acc: 0.9998\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00011249999806750566.\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.99830 to 0.99840, saving model to /root/model/cnnbestnew_429_6_600.h5\n",
      "90000/90000 [==============================] - 8s 94us/sample - loss: 8.2340e-04 - acc: 0.9998 - val_loss: 0.0074 - val_acc: 0.9984\n",
      "Epoch 13/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 5.0833e-04 - acc: 0.9998\n",
      "Epoch 00013: val_acc did not improve from 0.99840\n",
      "90000/90000 [==============================] - 5s 55us/sample - loss: 5.1128e-04 - acc: 0.9998 - val_loss: 0.0082 - val_acc: 0.9982\n",
      "Epoch 14/30\n",
      "89344/90000 [============================>.] - ETA: 0s - loss: 2.7977e-04 - acc: 0.9999\n",
      "Epoch 00014: val_acc did not improve from 0.99840\n",
      "90000/90000 [==============================] - 5s 56us/sample - loss: 2.7783e-04 - acc: 0.9999 - val_loss: 0.0081 - val_acc: 0.9984\n",
      "Epoch 15/30\n",
      "89344/90000 [============================>.] - ETA: 0s - loss: 2.4349e-04 - acc: 0.9999\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 5.624999903375283e-05.\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.99840\n",
      "90000/90000 [==============================] - 5s 55us/sample - loss: 2.4173e-04 - acc: 0.9999 - val_loss: 0.0084 - val_acc: 0.9982\n",
      "Epoch 16/30\n",
      "89088/90000 [============================>.] - ETA: 0s - loss: 2.7970e-04 - acc: 0.9999\n",
      "Epoch 00016: val_acc did not improve from 0.99840\n",
      "90000/90000 [==============================] - 5s 55us/sample - loss: 2.7746e-04 - acc: 0.9999 - val_loss: 0.0084 - val_acc: 0.9982\n",
      "Epoch 00016: early stopping\n",
      "32.0\n",
      "************************************ 随机种子600***第7折 ************************************\n",
      "Train on 90000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.9970\n",
      "Epoch 00001: val_acc improved from -inf to 0.99710, saving model to /root/model/cnnbestnew_429_7_600.h5\n",
      "90000/90000 [==============================] - 8s 92us/sample - loss: 0.0114 - acc: 0.9970 - val_loss: 0.0129 - val_acc: 0.9971\n",
      "Epoch 2/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9972\n",
      "Epoch 00002: val_acc did not improve from 0.99710\n",
      "90000/90000 [==============================] - 5s 55us/sample - loss: 0.0098 - acc: 0.9972 - val_loss: 0.0156 - val_acc: 0.9960\n",
      "Epoch 3/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9977\n",
      "Epoch 00003: val_acc did not improve from 0.99710\n",
      "90000/90000 [==============================] - 5s 55us/sample - loss: 0.0073 - acc: 0.9977 - val_loss: 0.0131 - val_acc: 0.9965\n",
      "Epoch 4/30\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9971\n",
      "Epoch 00004: val_acc did not improve from 0.99710\n",
      "90000/90000 [==============================] - 5s 56us/sample - loss: 0.0103 - acc: 0.9971 - val_loss: 0.0112 - val_acc: 0.9970\n",
      "Epoch 5/30\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9980\n",
      "Epoch 00005: val_acc improved from 0.99710 to 0.99770, saving model to /root/model/cnnbestnew_429_7_600.h5\n",
      "90000/90000 [==============================] - 6s 62us/sample - loss: 0.0067 - acc: 0.9980 - val_loss: 0.0087 - val_acc: 0.9977\n",
      "Epoch 6/30\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9980\n",
      "Epoch 00006: val_acc did not improve from 0.99770\n",
      "90000/90000 [==============================] - 5s 55us/sample - loss: 0.0074 - acc: 0.9980 - val_loss: 0.0114 - val_acc: 0.9970\n",
      "Epoch 7/30\n",
      "89088/90000 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9985\n",
      "Epoch 00007: val_acc did not improve from 0.99770\n",
      "90000/90000 [==============================] - 5s 56us/sample - loss: 0.0048 - acc: 0.9985 - val_loss: 0.0113 - val_acc: 0.9967\n",
      "Epoch 8/30\n",
      "89344/90000 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9977\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00044999999227002263.\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.99770\n",
      "90000/90000 [==============================] - 5s 56us/sample - loss: 0.0077 - acc: 0.9977 - val_loss: 0.0147 - val_acc: 0.9955\n",
      "Epoch 9/30\n",
      "89344/90000 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9990\n",
      "Epoch 00009: val_acc improved from 0.99770 to 0.99810, saving model to /root/model/cnnbestnew_429_7_600.h5\n",
      "90000/90000 [==============================] - 5s 60us/sample - loss: 0.0032 - acc: 0.9990 - val_loss: 0.0092 - val_acc: 0.9981\n",
      "Epoch 10/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 0.0010 - acc: 0.9997    \n",
      "Epoch 00010: val_acc did not improve from 0.99810\n",
      "90000/90000 [==============================] - 5s 57us/sample - loss: 0.0010 - acc: 0.9997 - val_loss: 0.0105 - val_acc: 0.9981\n",
      "Epoch 11/30\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9995\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00022499999613501132.\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.99810\n",
      "90000/90000 [==============================] - 5s 56us/sample - loss: 0.0018 - acc: 0.9995 - val_loss: 0.0098 - val_acc: 0.9980\n",
      "Epoch 12/30\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 8.0936e-04 - acc: 0.9997\n",
      "Epoch 00012: val_acc improved from 0.99810 to 0.99830, saving model to /root/model/cnnbestnew_429_7_600.h5\n",
      "90000/90000 [==============================] - 5s 60us/sample - loss: 8.0810e-04 - acc: 0.9997 - val_loss: 0.0084 - val_acc: 0.9983\n",
      "Epoch 13/30\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 4.3254e-04 - acc: 0.9999\n",
      "Epoch 00013: val_acc improved from 0.99830 to 0.99840, saving model to /root/model/cnnbestnew_429_7_600.h5\n",
      "90000/90000 [==============================] - 5s 61us/sample - loss: 4.3190e-04 - acc: 0.9999 - val_loss: 0.0101 - val_acc: 0.9984\n",
      "Epoch 14/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 4.7427e-04 - acc: 0.9998\n",
      "Epoch 00014: val_acc did not improve from 0.99840\n",
      "90000/90000 [==============================] - 5s 56us/sample - loss: 4.7524e-04 - acc: 0.9998 - val_loss: 0.0104 - val_acc: 0.9980\n",
      "Epoch 15/30\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 4.2276e-04 - acc: 0.9998\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00011249999806750566.\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.99840 to 0.99860, saving model to /root/model/cnnbestnew_429_7_600.h5\n",
      "90000/90000 [==============================] - 6s 61us/sample - loss: 4.2209e-04 - acc: 0.9998 - val_loss: 0.0092 - val_acc: 0.9986\n",
      "Epoch 16/30\n",
      "89344/90000 [============================>.] - ETA: 0s - loss: 3.3117e-04 - acc: 0.9999\n",
      "Epoch 00016: val_acc did not improve from 0.99860\n",
      "90000/90000 [==============================] - 5s 55us/sample - loss: 3.3128e-04 - acc: 0.9999 - val_loss: 0.0106 - val_acc: 0.9983\n",
      "Epoch 17/30\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 3.8042e-04 - acc: 0.9999\n",
      "Epoch 00017: val_acc did not improve from 0.99860\n",
      "90000/90000 [==============================] - 5s 56us/sample - loss: 3.7993e-04 - acc: 0.9999 - val_loss: 0.0115 - val_acc: 0.9985\n",
      "Epoch 18/30\n",
      "89088/90000 [============================>.] - ETA: 0s - loss: 2.4254e-04 - acc: 0.9999\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 5.624999903375283e-05.\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.99860\n",
      "90000/90000 [==============================] - 5s 55us/sample - loss: 2.4027e-04 - acc: 0.9999 - val_loss: 0.0118 - val_acc: 0.9984\n",
      "Epoch 19/30\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 1.6191e-04 - acc: 0.9999\n",
      "Epoch 00019: val_acc did not improve from 0.99860\n",
      "90000/90000 [==============================] - 5s 56us/sample - loss: 1.6165e-04 - acc: 0.9999 - val_loss: 0.0114 - val_acc: 0.9983\n",
      "Epoch 00019: early stopping\n",
      "28.0\n",
      "************************************ 随机种子600***第8折 ************************************\n",
      "Train on 90000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9968\n",
      "Epoch 00001: val_acc improved from -inf to 0.99630, saving model to /root/model/cnnbestnew_429_8_600.h5\n",
      "90000/90000 [==============================] - 6s 69us/sample - loss: 0.0117 - acc: 0.9968 - val_loss: 0.0121 - val_acc: 0.9963\n",
      "Epoch 2/30\n",
      "89344/90000 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9970\n",
      "Epoch 00002: val_acc did not improve from 0.99630\n",
      "90000/90000 [==============================] - 5s 55us/sample - loss: 0.0099 - acc: 0.9970 - val_loss: 0.0113 - val_acc: 0.9961\n",
      "Epoch 3/30\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 0.0082 - acc: 0.9976\n",
      "Epoch 00003: val_acc improved from 0.99630 to 0.99740, saving model to /root/model/cnnbestnew_429_8_600.h5\n",
      "90000/90000 [==============================] - 5s 59us/sample - loss: 0.0082 - acc: 0.9976 - val_loss: 0.0104 - val_acc: 0.9974\n",
      "Epoch 4/30\n",
      "89344/90000 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9974\n",
      "Epoch 00004: val_acc did not improve from 0.99740\n",
      "90000/90000 [==============================] - 5s 54us/sample - loss: 0.0085 - acc: 0.9973 - val_loss: 0.0078 - val_acc: 0.9970\n",
      "Epoch 5/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9981\n",
      "Epoch 00005: val_acc did not improve from 0.99740\n",
      "90000/90000 [==============================] - 5s 55us/sample - loss: 0.0055 - acc: 0.9981 - val_loss: 0.0098 - val_acc: 0.9973\n",
      "Epoch 6/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9979\n",
      "Epoch 00006: val_acc did not improve from 0.99740\n",
      "90000/90000 [==============================] - 5s 56us/sample - loss: 0.0078 - acc: 0.9979 - val_loss: 0.0138 - val_acc: 0.9963\n",
      "Epoch 7/30\n",
      "89344/90000 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9987\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00044999999227002263.\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.99740\n",
      "90000/90000 [==============================] - 5s 55us/sample - loss: 0.0049 - acc: 0.9987 - val_loss: 0.0117 - val_acc: 0.9966\n",
      "Epoch 00007: early stopping\n",
      "52.0\n",
      "************************************ 随机种子600***第9折 ************************************\n",
      "Train on 90000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9970\n",
      "Epoch 00001: val_acc improved from -inf to 0.99800, saving model to /root/model/cnnbestnew_429_9_600.h5\n",
      "90000/90000 [==============================] - 6s 70us/sample - loss: 0.0112 - acc: 0.9970 - val_loss: 0.0096 - val_acc: 0.9980\n",
      "Epoch 2/30\n",
      "89344/90000 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9974\n",
      "Epoch 00002: val_acc did not improve from 0.99800\n",
      "90000/90000 [==============================] - 5s 57us/sample - loss: 0.0087 - acc: 0.9975 - val_loss: 0.0293 - val_acc: 0.9931\n",
      "Epoch 3/30\n",
      "89088/90000 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9972\n",
      "Epoch 00003: val_acc did not improve from 0.99800\n",
      "90000/90000 [==============================] - 5s 56us/sample - loss: 0.0092 - acc: 0.9972 - val_loss: 0.0149 - val_acc: 0.9954\n",
      "Epoch 4/30\n",
      "89088/90000 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9974\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00044999999227002263.\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.99800\n",
      "90000/90000 [==============================] - 5s 56us/sample - loss: 0.0090 - acc: 0.9974 - val_loss: 0.0119 - val_acc: 0.9961\n",
      "Epoch 5/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9990\n",
      "Epoch 00005: val_acc did not improve from 0.99800\n",
      "90000/90000 [==============================] - 5s 55us/sample - loss: 0.0030 - acc: 0.9990 - val_loss: 0.0099 - val_acc: 0.9976\n",
      "Epoch 00005: early stopping\n",
      "40.0\n",
      "************************************ 随机种子600***第10折 ************************************\n",
      "Train on 90000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9969\n",
      "Epoch 00001: val_acc improved from -inf to 0.99430, saving model to /root/model/cnnbestnew_429_10_600.h5\n",
      "90000/90000 [==============================] - 6s 70us/sample - loss: 0.0115 - acc: 0.9969 - val_loss: 0.0225 - val_acc: 0.9943\n",
      "Epoch 2/30\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9971\n",
      "Epoch 00002: val_acc improved from 0.99430 to 0.99610, saving model to /root/model/cnnbestnew_429_10_600.h5\n",
      "90000/90000 [==============================] - 5s 60us/sample - loss: 0.0095 - acc: 0.9971 - val_loss: 0.0158 - val_acc: 0.9961\n",
      "Epoch 3/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9973\n",
      "Epoch 00003: val_acc did not improve from 0.99610\n",
      "90000/90000 [==============================] - 5s 55us/sample - loss: 0.0084 - acc: 0.9973 - val_loss: 0.0174 - val_acc: 0.9957\n",
      "Epoch 4/30\n",
      "89344/90000 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9982\n",
      "Epoch 00004: val_acc did not improve from 0.99610\n",
      "90000/90000 [==============================] - 5s 55us/sample - loss: 0.0063 - acc: 0.9982 - val_loss: 0.0208 - val_acc: 0.9954\n",
      "Epoch 5/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9977\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00044999999227002263.\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.99610 to 0.99620, saving model to /root/model/cnnbestnew_429_10_600.h5\n",
      "90000/90000 [==============================] - 5s 60us/sample - loss: 0.0075 - acc: 0.9977 - val_loss: 0.0169 - val_acc: 0.9962\n",
      "Epoch 6/30\n",
      "89088/90000 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9992\n",
      "Epoch 00006: val_acc improved from 0.99620 to 0.99720, saving model to /root/model/cnnbestnew_429_10_600.h5\n",
      "90000/90000 [==============================] - 6s 61us/sample - loss: 0.0029 - acc: 0.9992 - val_loss: 0.0138 - val_acc: 0.9972\n",
      "Epoch 7/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9996\n",
      "Epoch 00007: val_acc improved from 0.99720 to 0.99740, saving model to /root/model/cnnbestnew_429_10_600.h5\n",
      "90000/90000 [==============================] - 8s 84us/sample - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0122 - val_acc: 0.9974\n",
      "Epoch 8/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9996\n",
      "Epoch 00008: val_acc did not improve from 0.99740\n",
      "90000/90000 [==============================] - 5s 56us/sample - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0171 - val_acc: 0.9970\n",
      "Epoch 9/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9994\n",
      "Epoch 00009: val_acc did not improve from 0.99740\n",
      "90000/90000 [==============================] - 5s 56us/sample - loss: 0.0016 - acc: 0.9994 - val_loss: 0.0163 - val_acc: 0.9969\n",
      "Epoch 10/30\n",
      "89856/90000 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9994\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00022499999613501132.\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.99740\n",
      "90000/90000 [==============================] - 5s 57us/sample - loss: 0.0019 - acc: 0.9994 - val_loss: 0.0216 - val_acc: 0.9963\n",
      "Epoch 11/30\n",
      "89600/90000 [============================>.] - ETA: 0s - loss: 6.3408e-04 - acc: 0.9998\n",
      "Epoch 00011: val_acc did not improve from 0.99740\n",
      "90000/90000 [==============================] - 5s 55us/sample - loss: 6.5540e-04 - acc: 0.9998 - val_loss: 0.0213 - val_acc: 0.9968\n",
      "Epoch 00011: early stopping\n",
      "52.0\n",
      "score_mean:39.4\n"
     ]
    }
   ],
   "source": [
    "result = cv_model(X,Y,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = 0\n",
    "for i in range(10):\n",
    "    for seed in [2000]:\n",
    "        model = tf.keras.models.load_model('。/model/cnnbestnew_429_{}_{}.h5'.format(str(i+1),seed))\n",
    "        pred = model.predict(test)\n",
    "        preds+=pred\n",
    "temp = preds/10   #在172的model3上fintuing，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "tmp = 0\n",
    "for i in result:\n",
    "    tmp+=i\n",
    "tmp = tmp/10\n",
    "temp = pd.DataFrame(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 4)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3\n",
       "0  1.0  0.0  0.0  0.0\n",
       "1  0.0  0.0  1.0  0.0\n",
       "2  0.0  0.0  0.0  1.0\n",
       "3  1.0  0.0  0.0  0.0\n",
       "4  1.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp1 = pd.DataFrame(np.zeros((20000,4)))\n",
    "temp = pd.DataFrame(temp)\n",
    "for t in range(len(temp)):\n",
    "    a = temp.iloc[t,:].argmax(0)\n",
    "\n",
    "    temp1.iloc[t,a] = 1\n",
    "temp1.head()\n",
    "\n",
    "#此种方式相比用阈值分割处理，效果更佳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.read_csv('./submit/sample_submit.csv')\n",
    "results['label_0']=temp1[0]\n",
    "results['label_1']=temp1[1]\n",
    "results['label_2']=temp1[2]\n",
    "results['label_3']=temp1[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result = result/5\n",
    "# for i in range(len(result)):\n",
    "#     print(result.iloc[i,:])\n",
    "\n",
    "# for col in ['label_0','label_1','label_2','label_3']:\n",
    "#     results[col] = results[col].apply(lambda x:1 if x>0.5 else 0)\n",
    "    \n",
    "results.to_csv('./submit/cnnbest_4_29_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN_4_12_2.CSV  线下十折，每折样本10000，得分156，线上测试样本20000，得分173\n",
    "#cnnbest_   cnn_4_13_1.csv只在第一折初始化模型   线上191\n",
    "#cnnbest1_ cnn_4_13_2.csv每折都初始化模型  线下144.9  线上174\n",
    "#cnnbest2_{seed} cnn_4_14_1.csv  三组随机数，十折  线下137  以上前三层卷积核尺寸 32,16,16  线上174\n",
    "#cnnbest2_{seed} cnn_4_14_2.csv  三组随机数，十折  线下130  以上前三层卷积核尺寸 64,32,16   线上177\n",
    "#cnnbest_4_22_1.csv   ... ... ..             线下129.9 前三层32,16,16 \n",
    "#4231  seed700 十折 前三层的卷积核64,128,256 buildModel1   202\n",
    "#4232  seed700 十折  前两层相加输入第三层  线下129  buildmodel  //199,可能用的仍是buildModel1\n",
    "#4233 seed2000 十折  前三层相加   线下125 buildmodel2  cnnbestnew_422_{}_{}.h5\n",
    "#4241 seed2000 十折  前三层相加   线下117 buildmodel2  cnnbestnew_423_{}_{}.h5  监控valacc  线上188  \n",
    "#4242  和上述4241的模型一样，在最后数据处理部分，改用取最大值为正确类别\n",
    "#4252         前两层相加  卷积核32和64     192\n",
    "#4253         前两层相加  卷积核32和48        cnnbestnew_425_{}_{}.h5 \n",
    "#4261         model3前三层相加  卷积核32和48，16 + 归一化    cnnbestnew_425_{}_{}.h5  线下<118  4_26_1  线上172  **********best\n",
    "#4262         model4    cnnbestnew_426_{}_{}.h5  线下112.4   线上188   X\n",
    "#4263        model3   去掉了归一化层  线上192\n",
    "#4264         model3  没去掉归一化   用之前的模型425第一折作为预训练模型继续训练 随机种子2000 cnnbestnew_427_{}_{}.h5 线下42 线上168\n",
    "#4271        尝试用监控valacc去再跑一遍原本的那套cnn,换全连接层的激活函数 cnnbestnew_428_{}_{}.h5  线上198\n",
    "#4272       model3  没去掉归一化   用之前的模型作为预训练模型继续训练（425即线上172的模型）  cnnbestnew_428_{}_{}.h5  线下37.5  168  加入了测试集训练\n",
    "#4273       model3  没去掉归一化   用之前的模型作为预训练模型继续训练（427模型即线上168的作为与训练）  cnnbestnew_429_{}_{}.h5  线下13 178  初始学习率0.0009 加入了测试机训练\n",
    "#4291      model3  没去掉归一化   用之前的模型（425线上得分172的第一折）作为预训练模型继续训练 学习率0.0005  cnnbestnew_429_{}_{}.h5  三组随机数种子交叉验证 线下25  线上194"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#新思路，构造新的特征加到cnn，如均值，方差"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
